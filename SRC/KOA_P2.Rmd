---
title: "prelimexploration"
output: html_document
date: "2023-03-17"
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# Pre-processing

Load Libraries:
```{r}
library(tidyverse)
library(keras)
library(tensorflow)
library(reticulate)
```

Set up:
```{r}
label_list <- dir("Alzheimers Dataset/train/")
output_n <- length(label_list)
save(label_list, file="label_list.RData")

width <- 200
height<- 200
target_size <- c(width, height)
rgb <- 3 #color channels
```

Split data:
```{r}
path_train <- "Alzheimers Dataset/train/"
train_data_gen <- image_data_generator(rescale = 1/255, 
  validation_split = .2)
```

Generate train/validation objects:
```{r}
train_images <- flow_images_from_directory(path_train,
  train_data_gen,
  subset = 'training',
  target_size = target_size,
  class_mode = "categorical",
  shuffle=F,
  classes = label_list,
  seed = 2021)

validation_images <- flow_images_from_directory(path_train,
 train_data_gen, 
  subset = 'validation',
  target_size = target_size,
  class_mode = "categorical",
  classes = label_list,
  seed = 2021)


path_test <- "Alzheimers Dataset/test/"

test_data_gen <- image_data_generator(rescale = 1/255)

test_images <- flow_images_from_directory(path_test,
   test_data_gen,
   target_size = target_size,
   class_mode = "categorical",
   classes = label_list,
   shuffle = F,
   seed = 2021)
```

# Modeling

Training:
```{r}
mod_base <- application_xception(weights = 'imagenet', 
   include_top = FALSE, input_shape = c(width, height, 3))
freeze_weights(mod_base) 
```

Model function:
```{r}
model_function <- function(learning_rate = 0.001, 
  dropoutrate=0.2, n_dense=1024){
  
  k_clear_session()
  
  model <- keras_model_sequential() %>%
    mod_base %>% 
    layer_global_average_pooling_2d() %>% 
    layer_dense(units = n_dense) %>%
    layer_activation("relu") %>%
    layer_dropout(dropoutrate) %>%
    layer_dense(units=output_n, activation="softmax")
  
  model %>% compile(
    loss = "categorical_crossentropy",
    optimizer = optimizer_adam(learning_rate = learning_rate),
    metrics = "accuracy"
  )
  
  return(model)
  
}
```

```{r}
model <- model_function()

batch_size <- 32
epochs <- 6

hist <- model %>% fit(
  train_images,
  steps_per_epoch = train_images$n %/% batch_size, 
  epochs = epochs, 
  validation_data = validation_images,
  validation_steps = validation_images$n %/% batch_size,
  verbose = 2
)
```

```{r}
model %>% evaluate(test_images, 
                     steps = test_images$n %/% batch_size)
```

Predictions:
```{r}
predictions <- model %>% 
  predict(
    test_images,
    steps = test_images$n %/% batch_size
  ) %>% as.data.frame
```


```{r}
names(predictions) <- paste0("Class",0:3)

predictions$predicted_class <- 
  paste0("Class",apply(predictions,1,which.max)-1)
predictions$true_class <- paste0("Class",test_images$classes[1:1248])
```

```{r}
predictions %>% group_by(true_class) %>% 
  summarise(percentage_true = round(100*sum(predicted_class == 
    true_class)/n(),1)) %>% 
    left_join(data.frame(class= names(test_images$class_indices), 
    true_class=paste0("Class",0:3)),by="true_class") %>%
  select(class, percentage_true) %>% 
  mutate(class = fct_reorder(class,percentage_true)) %>%
  ggplot(aes(x=class,y=percentage_true,fill=percentage_true, 
    label=percentage_true)) +
  geom_col() + theme_minimal() + coord_flip() +
  geom_text(nudge_y = 3) + 
  ggtitle("Percentage correct classifications by Alzheimers Stage")
```

